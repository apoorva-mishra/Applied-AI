{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 1: Implementing TFIDF vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset):    \n",
    "    unique_words = set() # at first we will initialize an empty set\n",
    "    # check if its list type or not\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for row in dataset: # for each review in the dataset\n",
    "            for word in row.split(\" \"): # for each word in the review. #split method converts a string into list of words\n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                unique_words.add(word)\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"you need to pass list of sentance\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_freq(word, doc):\n",
    "    temp= dict(Counter(doc.split()))\n",
    "    if word in doc.split():\n",
    "        return temp[word]/sum(temp.values())\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_doc_freq(w, dataset):\n",
    "    num_of_sentences_having_w = 0\n",
    "    for row in dataset:\n",
    "        if w in row.split():\n",
    "            num_of_sentences_having_w+=1 \n",
    "    if num_of_sentences_having_w == len(dataset):\n",
    "        return 0\n",
    "    else:\n",
    "        return math.log(len(dataset)/(num_of_sentences_having_w+1))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(dataset,vocab):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, (list,)):\n",
    "        for idx, row in enumerate(tqdm(dataset)): # for each document in the dataset\n",
    "            # it will return a dict type object where key is the word and values is its frequency, {word:frequency}\n",
    "            word_freq = dict(Counter(row.split()))\n",
    "            # for every unique word in the document\n",
    "            for word, freq in word_freq.items():  # for each unique word in the review.                \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                # we will check if its there in the vocabulary that we build in fit() function\n",
    "                # dict.get() function will return the values, if the key doesn't exits it will return -1\n",
    "                col_index = vocab.get(word, -1) # retreving the dimension number of a word\n",
    "                # if the word exists\n",
    "                if col_index !=-1:\n",
    "                    # we are storing the index of the document\n",
    "                    rows.append(idx)\n",
    "                    # we are storing the dimensions of the word\n",
    "                    columns.append(col_index)\n",
    "                    # we are storing the frequency of the word\n",
    "                    values.append(term_freq(word,row)* inv_doc_freq(word, dataset))\n",
    "        return csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab)))\n",
    "    else:\n",
    "        print(\"you need to pass list of strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 746/746 [00:05<00:00, 147.86it/s]\n"
     ]
    }
   ],
   "source": [
    "X = transform(data,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2886 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Top 100 words with highest idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(dataset): \n",
    "    idfvalues=dict()\n",
    "    for row in dataset :\n",
    "        for word in row.split():\n",
    "            idf=inv_doc_freq(word, dataset)\n",
    "            idfvalues[word]=idf\n",
    "            \n",
    "    list_f_tuples = [(k,v) for k,v in idfvalues.items()]\n",
    "    \n",
    "    list_f_tuples.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    unique_words = set()\n",
    "    for word_idf in list_f_tuples[:100]:\n",
    "        unique_words.add(word_idf[0])\n",
    "    \n",
    "    unique_words = sorted(list(unique_words))\n",
    "    vocab = {j:i for i,j in enumerate(unique_words)}\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 746/746 [00:00<00:00, 9117.47it/s]\n"
     ]
    }
   ],
   "source": [
    "X= transform(data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7401973, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.7401973, 0.       , 0.       ,\n",
       "        0.7401973, 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
